# skillbox_sber_ml
Финальная работа введение в data science. Задача - выявить факторы, влияющие на вероятность клика.

Задание формулировалось следующим образом:


  1. Проведите подготовительную работу (один час):
     - Прочитайте предоставленный датасет.
     - Ознакомьтесь с описаниями представленных атрибутов.
     - Оцените полноту и чистоту данных. Попытайтесь понять, что стоит за этими данными в реальном мире. Приведите данные в удобный/нормальный вид для дальнейшей работы.
  2. Проведите разведочный анализ данных (четыре часа):
     - Проведите базовую чистку: дубликаты, пустые значения, типизация данных, ненужные атрибуты.
     - Посмотрите на распределение ключевых атрибутов, их отношения.
  3. Выполните задание согласно вашей специализации (18 часов):
     - Научитесь предсказывать совершение целевого действия (ориентировочное значение ROC-AUC ~ 0.65) — факт совершения пользователем целевого действия.
     - Упакуйте получившуюся модель в сервис, который будет брать на вход все атрибуты, типа utm_*, device_*, geo_*, и отдавать на выход 0/1 (1 — если пользователь совершит любое целевое действие).

Работа состояла из нескольких этапов:

1. Предварительный анализ
  - Посмотреть на данные и выявить примерную природу данных
  - Заполнить пустующие значения исходя из природы данных
  - Посмотреть на категориальные данные, насколько они влияют на переменную target (которую я тоже создал исходя из условий задания)
  - Удалить лишние колонки, не влияющие на результат
  - Преобразовать категориальные данные, по возможности уменьшив их размерность
  - Провести повторный анализ данных
2. Протестировать различные модели ML на даннных
  - Провести балансировку данных
  - Протестировать модели
  - Протестировать ансамбли   
3. Улучшить параметры модели
4. Выбрать подходящую модель исходя из значения roc-auc (основная метрика, т.к. данные несбалансированы
5. Поднять сервис через FastApi

Ссылки на образец исходных данных (1 млн строк)
https://disk.yandex.ru/d/33o0a3v-vWiYNg
https://disk.yandex.ru/d/z9C8m5U95EIedA

1. Предварительный анализ
   - Посмотреть на данные и выявить примерную природу данных.
     -- В данном случае имеем две таблицы с достаточно разношёрстными данными. Напрямую разбивать их по булевые колонки нельзя. Также некоторые можно превратить из категориальных в количественные,что неплохо. При этом данные сильно несбалансированы и это придётся учесть позже.
   - Заполнить пустующие значения исходя из природы данных.
      -- Поскольку подавляющее большинство данных имеет природу категориальную и пропуски были только в них, соответственно заполняем пустующие значения в основном категориями типа "другая" и считаем её как отдельную категорию.
   - Посмотреть на категориальные данные, насколько они влияют на переменную target (которую я тоже создал исходя из условий задания).
      -- Чёткие выраженные зависимости были, но радикальных отличий в зависимости от значений я не увидел. К тому же колонки были замусорены мелкими категориями, по которым невозможно было что-то понять.
   - Удалить лишние колонки, не влияющие на результат.
      -- Несколько колонок были удалены, такие как страна или модель устройства, потому что либо были слишком однородны, либо слишком неоднородны, либо слишком много отсутствующих данных чтобы их использовать. Также лишние колонки удалялись после их преобразоваия в более удобный для анализа вид.
   - Преобразовать категориальные данные, по возможности уменьшив их размерность
      -- Тут я смотрел насколько мелкие категории в данных исходя из графиков. Мелкие категории объединялись в категорию "другое", исходя из их влияния на результат. В каких-то категориях брал всего несколько самых крупных, в других (городах) до 50, в общем, смотрел туда, где выявлялось хоть сколько-  нибудь значимое количество
   - Провести повторный анализ данных
      -- После всех манипуляций я смотрел на данные и по необходимости повторял предыдущие шаги. Также преобразовал колонку разрешение экрана и время в количественные показатели (разрешение экрана использовал как "площадь экрана", умножив длину на ширину, рассудив что разных вариантов соотношений много, а влияет скорее всего именно площадь экрана на вероятность клика, если влияет. Время разбил по часам для упрощения анализа, опять же.

По второму пункту и далее особенно нечего добавить. Использовал, в основном, модели, которые работают быстро с большими данными, поэтому, скажем, SVM испольльзовать не удалось. Поэтому пробовал разные классификационные модели и остановился на бустингах, так как они давали лучший результат. Улучшить результат с помощью настройки параметров мне не удалось, roc-auc ансамбля из бустингов составлял примерно 69,9% на валидации и 69,2% на тесте, что выше бенчмарка в 65%, поднять выше не получилось, хотя и пытался. В процессе выполнения учёл, что балансировку нельзя делать на тестировачных данных, так как она искажает результат.
   

